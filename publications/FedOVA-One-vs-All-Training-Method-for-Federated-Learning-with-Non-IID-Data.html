<!DOCTYPE html><html><head><script async src="https://www.googletagmanager.com/gtag/js?id=UA-100898086-1"></script><script>if("localhost"!==window.location.hostname){function gtag(){dataLayer.push(arguments)}window.dataLayer=window.dataLayer||[],gtag("js",new Date),gtag("config","UA-100898086-1")}</script><meta content="IE=edge" http-equiv="X-UA-Compatible"><meta charset="utf-8"><meta content="width=device-width,initial-scale=1,minimum-scale=1,maximum-scale=1,user-scalable=no" name="viewport"><title>James Yu</title><link rel="stylesheet" href="/faculty/~james/css/style.css"><link href="https://fonts.googleapis.com/css?family=Open+Sans:300,400,700" rel="stylesheet"><meta name="generator" content="Hexo 5.2.0"></head><body><div class="wrapper"><nav><section class="nav container"><div><a href="/faculty/~james/">James Yu</a></div><div class="spring"></div><div class="menu-item"><a href="/faculty/~james/about.html"><span class="wide show">About Me</span><span class="wide hide">Me</span></a></div><span>/</span><div class="menu-item"><a href="/faculty/~james/publications.html"><span class="wide show">Publications</span><span class="wide hide">Pub</span></a></div><span>/</span><div class="menu-item"><a href="/faculty/~james/experiences.html"><span class="wide show">Experiences</span><span class="wide hide">Exp</span></a></div><span>/</span><div class="menu-item"><a href="/faculty/~james/scai/"><span class="wide show">SCAI Lab</span><span class="wide hide">Lab</span></a></div></section></nav><div class="pub content"><section class="one column container"><div style="text-align:center"><h2>FedOVA: One-vs-All Training Method for Federated Learning with Non-IID Data</h2><h4>Yuanshao Zhu, Christos Markos, Ruihui Zhao, Yefeng Zheng, and James J.Q. Yu*<br>Proc. International Joint Conference on Neural Networks, Shenzhen, China, Jul. 2021</h4></div><p>Federated Learning (FL) is a privacy-oriented framework that allows distributed edge devices to jointly train a shared global model without transmitting their sensed data to centralized servers. FL aims to balance the naturally conflicting objectives of obtaining massive amounts of data while protecting sensitive information. However, the data stored locally on each edge device are typically not independent and identically distributed (non-IID). Such data heterogeneity poses a severe statistical challenge for the optimization and convergence of the global model. In response to this issue, we propose Federated One-vs-All (FedOVA), an efficient FL algorithm that first decomposes a multi-class classification problem into more straightforward binary classification problems and then combines their respective outputs using ensemble learning. Experiments on several public datasets show that FedOVA achieves higher accuracy and faster convergence than federated averaging and data sharing. Furthermore, our approach can support practical settings with a large number of clients (up to 1000 clients) in FL.</p><div class="centered"><h4><a href="javascript:copy()">Copy Citation</a></h4><script>let citation = `Yuanshao Zhu, Christos Markos, Ruihui Zhao, Yefeng Zheng, and James J.Q. Yu, "FedOVA: One-vs-All Training Method for Federated Learning with Non-IID Data," in Proc. International Joint Conference on Neural Networks, Shenzhen, China, Jul. 2021.`
function copy() {
    navigator.clipboard.writeText(citation)
}</script></div></section></div><footer><section class="footer container">© James Yu 2009–2021</section></footer></div></body></html>