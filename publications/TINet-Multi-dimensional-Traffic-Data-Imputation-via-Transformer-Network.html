<!DOCTYPE html><html><head><script async src="https://www.googletagmanager.com/gtag/js?id=UA-100898086-1"></script><script>if("localhost"!==window.location.hostname){function gtag(){dataLayer.push(arguments)}window.dataLayer=window.dataLayer||[],gtag("js",new Date),gtag("config","UA-100898086-1")}</script><meta content="IE=edge" http-equiv="X-UA-Compatible"><meta charset="utf-8"><meta content="width=device-width,initial-scale=1,minimum-scale=1,maximum-scale=1,user-scalable=no" name="viewport"><title>James Yu</title><link rel="stylesheet" href="/css/style.css"><link href="https://fonts.googleapis.com/css?family=Open+Sans:300,400,700" rel="stylesheet"><meta name="generator" content="Hexo 5.2.0"></head><body><div class="wrapper"><nav><section class="nav container"><div><a href="/">James Yu</a></div><div class="spring"></div><div class="menu-item"><a href="/about.html"><span class="wide show">About Me</span><span class="wide hide">Me</span></a></div><span>/</span><div class="menu-item"><a href="/publications.html"><span class="wide show">Publications</span><span class="wide hide">Pub</span></a></div><span>/</span><div class="menu-item"><a href="/experiences.html"><span class="wide show">Experiences</span><span class="wide hide">Exp</span></a></div><span>/</span><div class="menu-item"><a href="/scai/"><span class="wide show">SCAI Lab</span><span class="wide hide">Lab</span></a></div></section></nav><div class="pub content"><section class="one column container"><div style="text-align:center"><h2>TINet: Multi-dimensional Traffic Data Imputation via Transformer Network</h2><h4>Xiaozhuang Song, Yongchao Ye, and James J.Q. Yu*<br>Proc. IEEE International Conference on Artificial Neural Networks, Bratislava, Slovakia, Sept. 2021</h4></div><p>Missing traffic data problem has a significant negative impact for data-driven applications in Intelligent Transportation Systems (ITS). However, existing models mainly focus on the imputation results under Missing Completely At Random (MCAR) task, and there is a considerable difference between MCAR with the situation encountered in real life. Furthermore, some existing state-of-the-art models can be vulnerable when dealing with other imputation tasks like block miss imputation. In this paper, we propose a novel deep learning model TINet for missing traffic data imputation problems. TINet uses the self-attention mechanism to dynamically adjust the weight for each entries in the input data. This architecture effectively avoids the limitation of the Fully Connected Network (FCN). Furthermore, TINet uses multi-dimensional embedding for representing data&#39;s spatial-temporal positional information, which alleviates the computation and memory requirements of attention-based model for multi-dimentional data. We evaluate TINet with other baselines on two real-world datasets. Different from the previous work that only employs MCAR for testing, our experiment also tested the performance of models on the Block Miss At Random (BMAR) tasks. The results show that TINet outperforms baseline imputation models for both MCAR and BMAR tasks with different missing rates.</p><div class="centered"><h4><a href="http://cse.sustech.edu.cn/faculty/~james/files/publications/TINet-Multi-dimensional-Traffic-Data-Imputation-via-Transformer-Network.pdf" target="_blank">Download PDF</a></h4><h4><a href="javascript:copy()">Copy Citation</a></h4><script>let citation = `Xiaozhuang Song, Yongchao Ye, and James J.Q. Yu, "TINet: Multi-dimensional Traffic Data Imputation via Transformer Network," in Proc. IEEE International Conference on Artificial Neural Networks, Bratislava, Slovakia, Sept. 2021.`
function copy() {
    navigator.clipboard.writeText(citation)
}</script></div></section></div><footer><section class="footer container">© James Yu 2009–2021</section></footer></div></body></html>